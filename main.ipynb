{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import library\n",
    "\n",
    "import pandas as pd \n",
    "# import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cleanlab.classification import CleanLearning\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras import backend as K\n",
    "from cleanlab import *\n",
    "from torch import nn\n",
    "import torch as torch\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cleanlab.filter import find_label_issues\n",
    "from cleanlab.dataset import health_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â Load the datas \n",
    "\n",
    "fmnist_test = pd.read_csv('fashion-mnist_test.csv')\n",
    "fmnist_train = pd.read_csv('fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort datas in x and y \n",
    "\n",
    "label_fmnist_test = fmnist_test.iloc[:,0]\n",
    "label_fmnist_train = fmnist_train.iloc[:,0]\n",
    "fmnist_test = fmnist_test.iloc[:,1:]\n",
    "fmnist_train = fmnist_train.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Our label is jsute a number,\n",
    "\n",
    "label_fmnist_test.shape\n",
    "Y_test = label_fmnist_test.to_numpy()\n",
    "Y_test = Y_test.astype('int32')\n",
    "# Y_test = torch.from_numpy(Y_test)\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize\n",
    "\n",
    "normalized_fmnist_test = fmnist_test /255\n",
    "normalized_fmnist_train = fmnist_train /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We then constructs our pictures \n",
    "fashion_test = np.array(normalized_fmnist_test)\n",
    "fashion_test = fashion_test.reshape(len(fashion_test),1,28,28)\n",
    "fashion_test = fashion_test.astype('float32')\n",
    "\n",
    "fashion_train = np.array(normalized_fmnist_train)\n",
    "fashion_train = fashion_train.reshape(len(fashion_train),1,28,28)\n",
    "fashion_train = fashion_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdb87027160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Show if its good \n",
    "exemple_image = fashion_test[77,0,:,:]\n",
    "plt.imshow(exemple_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.cnn(X)\n",
    "        X = self.out(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_skorch = NeuralNetClassifier(ClassifierModule, max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craven/miniconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.9273\u001b[0m       \u001b[32m0.6262\u001b[0m        \u001b[35m1.8492\u001b[0m  3.6469\n",
      "      2        \u001b[36m1.1768\u001b[0m       \u001b[32m0.7481\u001b[0m        \u001b[35m0.9410\u001b[0m  0.5628\n",
      "      3        \u001b[36m0.8411\u001b[0m       \u001b[32m0.7681\u001b[0m        \u001b[35m0.7419\u001b[0m  0.5609\n",
      "      4        \u001b[36m0.7040\u001b[0m       \u001b[32m0.7800\u001b[0m        \u001b[35m0.6530\u001b[0m  0.5774\n",
      "      5        \u001b[36m0.6325\u001b[0m       \u001b[32m0.7894\u001b[0m        \u001b[35m0.6045\u001b[0m  0.5435\n",
      "      6        \u001b[36m0.5864\u001b[0m       \u001b[32m0.7956\u001b[0m        \u001b[35m0.5713\u001b[0m  0.5226\n",
      "      7        \u001b[36m0.5521\u001b[0m       \u001b[32m0.7994\u001b[0m        \u001b[35m0.5457\u001b[0m  0.5233\n",
      "      8        \u001b[36m0.5245\u001b[0m       \u001b[32m0.8063\u001b[0m        \u001b[35m0.5270\u001b[0m  0.5150\n",
      "      9        \u001b[36m0.5013\u001b[0m       \u001b[32m0.8137\u001b[0m        \u001b[35m0.5112\u001b[0m  0.5113\n",
      "     10        \u001b[36m0.4813\u001b[0m       \u001b[32m0.8194\u001b[0m        \u001b[35m0.4976\u001b[0m  0.5061\n",
      "     11        \u001b[36m0.4635\u001b[0m       \u001b[32m0.8237\u001b[0m        \u001b[35m0.4859\u001b[0m  0.5220\n",
      "     12        \u001b[36m0.4476\u001b[0m       \u001b[32m0.8244\u001b[0m        \u001b[35m0.4757\u001b[0m  0.5210\n",
      "     13        \u001b[36m0.4331\u001b[0m       \u001b[32m0.8275\u001b[0m        \u001b[35m0.4681\u001b[0m  0.5121\n",
      "     14        \u001b[36m0.4195\u001b[0m       \u001b[32m0.8287\u001b[0m        \u001b[35m0.4595\u001b[0m  0.5156\n",
      "     15        \u001b[36m0.4073\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m0.4524\u001b[0m  0.5128\n",
      "     16        \u001b[36m0.3961\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4453\u001b[0m  0.5105\n",
      "     17        \u001b[36m0.3858\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m0.4404\u001b[0m  0.5073\n",
      "     18        \u001b[36m0.3761\u001b[0m       0.8394        \u001b[35m0.4365\u001b[0m  0.5132\n",
      "     19        \u001b[36m0.3672\u001b[0m       \u001b[32m0.8413\u001b[0m        \u001b[35m0.4313\u001b[0m  0.5207\n",
      "     20        \u001b[36m0.3587\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4276\u001b[0m  0.5174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craven/miniconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7337\u001b[0m       \u001b[32m0.6369\u001b[0m        \u001b[35m1.5525\u001b[0m  0.5241\n",
      "      2        \u001b[36m1.0523\u001b[0m       \u001b[32m0.7306\u001b[0m        \u001b[35m0.8861\u001b[0m  0.5216\n",
      "      3        \u001b[36m0.8156\u001b[0m       \u001b[32m0.7525\u001b[0m        \u001b[35m0.7395\u001b[0m  0.5282\n",
      "      4        \u001b[36m0.7097\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.6656\u001b[0m  0.5379\n",
      "      5        \u001b[36m0.6475\u001b[0m       \u001b[32m0.7856\u001b[0m        \u001b[35m0.6197\u001b[0m  0.5321\n",
      "      6        \u001b[36m0.6040\u001b[0m       \u001b[32m0.7963\u001b[0m        \u001b[35m0.5877\u001b[0m  0.5250\n",
      "      7        \u001b[36m0.5702\u001b[0m       0.7963        \u001b[35m0.5626\u001b[0m  0.5447\n",
      "      8        \u001b[36m0.5423\u001b[0m       \u001b[32m0.8037\u001b[0m        \u001b[35m0.5422\u001b[0m  0.5833\n",
      "      9        \u001b[36m0.5185\u001b[0m       \u001b[32m0.8100\u001b[0m        \u001b[35m0.5248\u001b[0m  0.5819\n",
      "     10        \u001b[36m0.4978\u001b[0m       \u001b[32m0.8163\u001b[0m        \u001b[35m0.5099\u001b[0m  0.5010\n",
      "     11        \u001b[36m0.4792\u001b[0m       \u001b[32m0.8200\u001b[0m        \u001b[35m0.4966\u001b[0m  0.4066\n",
      "     12        \u001b[36m0.4621\u001b[0m       \u001b[32m0.8263\u001b[0m        \u001b[35m0.4847\u001b[0m  0.3998\n",
      "     13        \u001b[36m0.4464\u001b[0m       \u001b[32m0.8300\u001b[0m        \u001b[35m0.4738\u001b[0m  0.4001\n",
      "     14        \u001b[36m0.4322\u001b[0m       \u001b[32m0.8350\u001b[0m        \u001b[35m0.4638\u001b[0m  0.4013\n",
      "     15        \u001b[36m0.4193\u001b[0m       \u001b[32m0.8375\u001b[0m        \u001b[35m0.4544\u001b[0m  0.4562\n",
      "     16        \u001b[36m0.4075\u001b[0m       0.8369        \u001b[35m0.4461\u001b[0m  0.5267\n",
      "     17        \u001b[36m0.3964\u001b[0m       \u001b[32m0.8400\u001b[0m        \u001b[35m0.4388\u001b[0m  0.4544\n",
      "     18        \u001b[36m0.3861\u001b[0m       \u001b[32m0.8469\u001b[0m        \u001b[35m0.4314\u001b[0m  0.4117\n",
      "     19        \u001b[36m0.3764\u001b[0m       \u001b[32m0.8506\u001b[0m        \u001b[35m0.4261\u001b[0m  0.3954\n",
      "     20        \u001b[36m0.3673\u001b[0m       0.8500        \u001b[35m0.4190\u001b[0m  0.5335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craven/miniconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7778\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m1.7329\u001b[0m  0.4012\n",
      "      2        \u001b[36m1.0374\u001b[0m       \u001b[32m0.7400\u001b[0m        \u001b[35m0.8734\u001b[0m  0.5191\n",
      "      3        \u001b[36m0.7947\u001b[0m       \u001b[32m0.7600\u001b[0m        \u001b[35m0.7280\u001b[0m  0.4032\n",
      "      4        \u001b[36m0.6976\u001b[0m       \u001b[32m0.7688\u001b[0m        \u001b[35m0.6615\u001b[0m  0.3932\n",
      "      5        \u001b[36m0.6408\u001b[0m       \u001b[32m0.7788\u001b[0m        \u001b[35m0.6215\u001b[0m  0.4738\n",
      "      6        \u001b[36m0.6006\u001b[0m       \u001b[32m0.7863\u001b[0m        \u001b[35m0.5925\u001b[0m  0.5191\n",
      "      7        \u001b[36m0.5695\u001b[0m       \u001b[32m0.7919\u001b[0m        \u001b[35m0.5713\u001b[0m  0.5691\n",
      "      8        \u001b[36m0.5435\u001b[0m       \u001b[32m0.7950\u001b[0m        \u001b[35m0.5510\u001b[0m  0.5557\n",
      "      9        \u001b[36m0.5207\u001b[0m       \u001b[32m0.8100\u001b[0m        \u001b[35m0.5327\u001b[0m  0.5341\n",
      "     10        \u001b[36m0.5001\u001b[0m       \u001b[32m0.8113\u001b[0m        \u001b[35m0.5175\u001b[0m  0.5554\n",
      "     11        \u001b[36m0.4818\u001b[0m       \u001b[32m0.8175\u001b[0m        \u001b[35m0.5025\u001b[0m  0.5798\n",
      "     12        \u001b[36m0.4650\u001b[0m       \u001b[32m0.8244\u001b[0m        \u001b[35m0.4915\u001b[0m  0.4838\n",
      "     13        \u001b[36m0.4498\u001b[0m       \u001b[32m0.8269\u001b[0m        \u001b[35m0.4804\u001b[0m  0.4849\n",
      "     14        \u001b[36m0.4356\u001b[0m       \u001b[32m0.8300\u001b[0m        \u001b[35m0.4702\u001b[0m  0.4129\n",
      "     15        \u001b[36m0.4225\u001b[0m       \u001b[32m0.8313\u001b[0m        \u001b[35m0.4608\u001b[0m  0.4167\n",
      "     16        \u001b[36m0.4103\u001b[0m       \u001b[32m0.8350\u001b[0m        \u001b[35m0.4527\u001b[0m  0.4766\n",
      "     17        \u001b[36m0.3989\u001b[0m       \u001b[32m0.8394\u001b[0m        \u001b[35m0.4444\u001b[0m  0.4056\n",
      "     18        \u001b[36m0.3882\u001b[0m       \u001b[32m0.8438\u001b[0m        \u001b[35m0.4378\u001b[0m  0.3866\n",
      "     19        \u001b[36m0.3783\u001b[0m       \u001b[32m0.8450\u001b[0m        \u001b[35m0.4316\u001b[0m  0.3852\n",
      "     20        \u001b[36m0.3687\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.4260\u001b[0m  0.4230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craven/miniconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7941\u001b[0m       \u001b[32m0.6344\u001b[0m        \u001b[35m1.6145\u001b[0m  0.5239\n",
      "      2        \u001b[36m1.1503\u001b[0m       \u001b[32m0.7369\u001b[0m        \u001b[35m0.9531\u001b[0m  0.5335\n",
      "      3        \u001b[36m0.8584\u001b[0m       \u001b[32m0.7675\u001b[0m        \u001b[35m0.7729\u001b[0m  0.5214\n",
      "      4        \u001b[36m0.7273\u001b[0m       \u001b[32m0.7769\u001b[0m        \u001b[35m0.6813\u001b[0m  0.5282\n",
      "      5        \u001b[36m0.6533\u001b[0m       \u001b[32m0.7869\u001b[0m        \u001b[35m0.6277\u001b[0m  0.5248\n",
      "      6        \u001b[36m0.6036\u001b[0m       \u001b[32m0.7956\u001b[0m        \u001b[35m0.5886\u001b[0m  0.5241\n",
      "      7        \u001b[36m0.5663\u001b[0m       \u001b[32m0.8037\u001b[0m        \u001b[35m0.5608\u001b[0m  0.5182\n",
      "      8        \u001b[36m0.5361\u001b[0m       \u001b[32m0.8094\u001b[0m        \u001b[35m0.5368\u001b[0m  0.4075\n",
      "      9        \u001b[36m0.5108\u001b[0m       \u001b[32m0.8100\u001b[0m        \u001b[35m0.5182\u001b[0m  0.3894\n",
      "     10        \u001b[36m0.4888\u001b[0m       \u001b[32m0.8150\u001b[0m        \u001b[35m0.5028\u001b[0m  0.4000\n",
      "     11        \u001b[36m0.4696\u001b[0m       \u001b[32m0.8213\u001b[0m        \u001b[35m0.4891\u001b[0m  0.3884\n",
      "     12        \u001b[36m0.4523\u001b[0m       \u001b[32m0.8244\u001b[0m        \u001b[35m0.4778\u001b[0m  0.5151\n",
      "     13        \u001b[36m0.4369\u001b[0m       \u001b[32m0.8263\u001b[0m        \u001b[35m0.4670\u001b[0m  0.5267\n",
      "     14        \u001b[36m0.4231\u001b[0m       \u001b[32m0.8294\u001b[0m        \u001b[35m0.4586\u001b[0m  0.5322\n",
      "     15        \u001b[36m0.4110\u001b[0m       0.8256        \u001b[35m0.4530\u001b[0m  0.4456\n",
      "     16        \u001b[36m0.3997\u001b[0m       \u001b[32m0.8337\u001b[0m        \u001b[35m0.4432\u001b[0m  0.3995\n",
      "     17        \u001b[36m0.3900\u001b[0m       \u001b[32m0.8375\u001b[0m        \u001b[35m0.4385\u001b[0m  0.3977\n",
      "     18        \u001b[36m0.3798\u001b[0m       0.8331        0.4423  0.3981\n",
      "     19        \u001b[36m0.3710\u001b[0m       \u001b[32m0.8419\u001b[0m        \u001b[35m0.4267\u001b[0m  0.5249\n",
      "     20        \u001b[36m0.3635\u001b[0m       \u001b[32m0.8431\u001b[0m        \u001b[35m0.4231\u001b[0m  0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craven/miniconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7601\u001b[0m       \u001b[32m0.5819\u001b[0m        \u001b[35m1.4880\u001b[0m  0.5198\n",
      "      2        \u001b[36m1.1394\u001b[0m       \u001b[32m0.6919\u001b[0m        \u001b[35m0.9853\u001b[0m  0.5184\n",
      "      3        \u001b[36m0.8843\u001b[0m       \u001b[32m0.7362\u001b[0m        \u001b[35m0.8178\u001b[0m  0.5161\n",
      "      4        \u001b[36m0.7584\u001b[0m       \u001b[32m0.7556\u001b[0m        \u001b[35m0.7297\u001b[0m  0.4544\n",
      "      5        \u001b[36m0.6848\u001b[0m       \u001b[32m0.7625\u001b[0m        \u001b[35m0.6739\u001b[0m  0.3838\n",
      "      6        \u001b[36m0.6365\u001b[0m       \u001b[32m0.7738\u001b[0m        \u001b[35m0.6373\u001b[0m  0.4075\n",
      "      7        \u001b[36m0.6015\u001b[0m       \u001b[32m0.7781\u001b[0m        \u001b[35m0.6104\u001b[0m  0.4054\n",
      "      8        \u001b[36m0.5737\u001b[0m       \u001b[32m0.7887\u001b[0m        \u001b[35m0.5906\u001b[0m  0.4435\n",
      "      9        \u001b[36m0.5506\u001b[0m       \u001b[32m0.7950\u001b[0m        \u001b[35m0.5733\u001b[0m  0.4023\n",
      "     10        \u001b[36m0.5306\u001b[0m       \u001b[32m0.7994\u001b[0m        \u001b[35m0.5583\u001b[0m  0.4040\n",
      "     11        \u001b[36m0.5129\u001b[0m       \u001b[32m0.8050\u001b[0m        \u001b[35m0.5463\u001b[0m  0.4225\n",
      "     12        \u001b[36m0.4967\u001b[0m       \u001b[32m0.8094\u001b[0m        \u001b[35m0.5359\u001b[0m  0.4732\n",
      "     13        \u001b[36m0.4820\u001b[0m       \u001b[32m0.8137\u001b[0m        \u001b[35m0.5270\u001b[0m  0.4695\n",
      "     14        \u001b[36m0.4685\u001b[0m       0.8137        \u001b[35m0.5191\u001b[0m  0.4247\n",
      "     15        \u001b[36m0.4560\u001b[0m       \u001b[32m0.8163\u001b[0m        \u001b[35m0.5114\u001b[0m  0.4231\n",
      "     16        \u001b[36m0.4445\u001b[0m       \u001b[32m0.8194\u001b[0m        \u001b[35m0.5054\u001b[0m  0.4148\n",
      "     17        \u001b[36m0.4339\u001b[0m       \u001b[32m0.8200\u001b[0m        \u001b[35m0.4992\u001b[0m  0.3994\n",
      "     18        \u001b[36m0.4239\u001b[0m       0.8194        \u001b[35m0.4955\u001b[0m  0.4328\n",
      "     19        \u001b[36m0.4145\u001b[0m       \u001b[32m0.8213\u001b[0m        \u001b[35m0.4921\u001b[0m  0.4613\n",
      "     20        \u001b[36m0.4059\u001b[0m       \u001b[32m0.8275\u001b[0m        \u001b[35m0.4895\u001b[0m  0.5390\n"
     ]
    }
   ],
   "source": [
    "y = Y_test\n",
    "X = fashion_test\n",
    "num_crossval_folds = 5\n",
    "pred_probs = cross_val_predict(model_skorch, X, y,\n",
    "                               cv=num_crossval_folds,\n",
    "                               method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated estimate of accuracy on held-out data: 0.8411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_labels = pred_probs.argmax(axis=1)\n",
    "acc = accuracy_score(y, predicted_labels)\n",
    "\n",
    "print(f\"Cross-validated estimate of accuracy on held-out data: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanlab found 752 label issues.\n",
      "Here are the indices of the top 15 most likely label errors:\n",
      "[5232 8042 8950 1178 2128 5076 1585 3591 2313 2224 4989 6512 1961 3558\n",
      " 9330]\n"
     ]
    }
   ],
   "source": [
    "method = 'both'\n",
    "ranked_label_issues = find_label_issues(y, pred_probs,filter_by=method,return_indices_ranked_by=\"self_confidence\")\n",
    "\n",
    "print(f\"Cleanlab found {len(ranked_label_issues)} label issues.\")\n",
    "print(\"Here are the indices of the top 15 most likely label errors:\\n\"\n",
    "      f\"{ranked_label_issues[:15]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dico = {\n",
    "    '0':'T-shirt/top',\n",
    "    '1':'Trouser',\n",
    "    '2':'Pullover',\n",
    "    '3':'Dress',\n",
    "    '4':'Coat',\n",
    "    '5':'Sandal',\n",
    "    '6':'Shirt',\n",
    "    '7':'Sneaker',\n",
    "    '8':'Bag',\n",
    "    '9':'Ankle boot'\n",
    "}\n",
    "def plot_examples(id_iter, nrows=1, ncols=1):\n",
    "    for count, id in enumerate(id_iter):\n",
    "        plt.subplot(nrows, ncols, count + 1)\n",
    "        plt.imshow(X[id].reshape(28, 28), cmap=\"gray\")\n",
    "        fashion_id = str(y[id])\n",
    "        plt.title(f\"id: {id} \\n label: {fashion_dico[fashion_id]}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(h_pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ranked_label_issues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_examples(ranked_label_issues[\u001b[39mrange\u001b[39m(\u001b[39m15\u001b[39m)], \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ranked_label_issues' is not defined"
     ]
    }
   ],
   "source": [
    "plot_examples(ranked_label_issues[range(15)], 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "|  Generating a Cleanlab Dataset Health Summary            |\n",
      "|   for your dataset with 10,000 examples and 10 classes.  |\n",
      "|  Note, Cleanlab is not a medical doctor... yet.          |\n",
      "------------------------------------------------------------\n",
      "\n",
      "Overall Class Quality and Noise across your dataset (below)\n",
      "------------------------------------------------------------ \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Label Issues</th>\n",
       "      <th>Inverse Label Issues</th>\n",
       "      <th>Label Noise</th>\n",
       "      <th>Inverse Label Noise</th>\n",
       "      <th>Label Quality Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>290</td>\n",
       "      <td>361</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.337068</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>110</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.117021</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "      <td>181</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.176413</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>157</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.152872</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.024185</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.014056</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index  Label Issues  Inverse Label Issues  Label Noise  \\\n",
       "0            6           290                   361        0.290   \n",
       "1            2           170                   110        0.170   \n",
       "2            4           155                   181        0.155   \n",
       "3            0           130                   157        0.130   \n",
       "4            3            72                    23        0.072   \n",
       "5            5            20                     7        0.020   \n",
       "6            9            18                    14        0.018   \n",
       "7            7            16                    30        0.016   \n",
       "8            1            14                     2        0.014   \n",
       "9            8            13                    13        0.013   \n",
       "\n",
       "   Inverse Label Noise  Label Quality Score  \n",
       "0             0.337068                0.710  \n",
       "1             0.117021                0.830  \n",
       "2             0.176413                0.845  \n",
       "3             0.152872                0.870  \n",
       "4             0.024185                0.928  \n",
       "5             0.007092                0.980  \n",
       "6             0.014056                0.982  \n",
       "7             0.029586                0.984  \n",
       "8             0.002024                0.986  \n",
       "9             0.013000                0.987  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Overlap. In some cases, you may want to merge classes in the top rows (below)\n",
      "-----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index A</th>\n",
       "      <th>Class Index B</th>\n",
       "      <th>Num Overlapping Examples</th>\n",
       "      <th>Joint Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>242</td>\n",
       "      <td>0.0242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>206</td>\n",
       "      <td>0.0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>157</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class Index A  Class Index B  Num Overlapping Examples  Joint Probability\n",
       "0               0              6                       242             0.0242\n",
       "1               4              6                       206             0.0206\n",
       "2               2              6                       157             0.0157\n",
       "3               2              4                        98             0.0098\n",
       "4               7              9                        27             0.0027\n",
       "5               0              3                        26             0.0026\n",
       "6               3              6                        26             0.0026\n",
       "7               3              4                        26             0.0026\n",
       "8               5              7                        19             0.0019\n",
       "9               0              2                        13             0.0013\n",
       "10              6              8                        13             0.0013\n",
       "11              2              3                        10             0.0010\n",
       "12              1              3                         7             0.0007\n",
       "13              1              6                         7             0.0007\n",
       "14              5              9                         5             0.0005\n",
       "15              4              8                         4             0.0004\n",
       "16              0              8                         4             0.0004\n",
       "17              5              8                         3             0.0003\n",
       "18              0              4                         2             0.0002\n",
       "19              1              8                         1             0.0001\n",
       "20              1              2                         1             0.0001\n",
       "21              2              8                         1             0.0001\n",
       "22              4              5                         0             0.0000\n",
       "23              6              7                         0             0.0000\n",
       "24              6              9                         0             0.0000\n",
       "25              5              6                         0             0.0000\n",
       "26              4              9                         0             0.0000\n",
       "27              7              8                         0             0.0000\n",
       "28              4              7                         0             0.0000\n",
       "29              0              1                         0             0.0000\n",
       "30              3              9                         0             0.0000\n",
       "31              3              8                         0             0.0000\n",
       "32              3              7                         0             0.0000\n",
       "33              3              5                         0             0.0000\n",
       "34              2              9                         0             0.0000\n",
       "35              2              7                         0             0.0000\n",
       "36              2              5                         0             0.0000\n",
       "37              1              9                         0             0.0000\n",
       "38              1              7                         0             0.0000\n",
       "39              1              5                         0             0.0000\n",
       "40              1              4                         0             0.0000\n",
       "41              0              9                         0             0.0000\n",
       "42              0              7                         0             0.0000\n",
       "43              0              5                         0             0.0000\n",
       "44              8              9                         0             0.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * Overall, about 9% (898 of the 10,000) labels in your dataset have potential issues.\n",
      " ** The overall label health score for this dataset is: 0.91.\n",
      "\n",
      "Generated with <3 from Cleanlab.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overall_label_health_score': 0.9102,\n",
       " 'joint': array([[0.087 , 0.    , 0.0012, 0.0007, 0.    , 0.    , 0.0108, 0.    ,\n",
       "         0.0003, 0.    ],\n",
       "        [0.    , 0.0986, 0.0001, 0.0006, 0.    , 0.    , 0.0007, 0.    ,\n",
       "         0.    , 0.    ],\n",
       "        [0.0001, 0.    , 0.083 , 0.    , 0.0076, 0.    , 0.0093, 0.    ,\n",
       "         0.    , 0.    ],\n",
       "        [0.0019, 0.0001, 0.001 , 0.0928, 0.0019, 0.    , 0.0023, 0.    ,\n",
       "         0.    , 0.    ],\n",
       "        [0.0002, 0.    , 0.0022, 0.0007, 0.0845, 0.    , 0.0122, 0.    ,\n",
       "         0.0002, 0.    ],\n",
       "        [0.    , 0.    , 0.    , 0.    , 0.    , 0.098 , 0.    , 0.0012,\n",
       "         0.0003, 0.0005],\n",
       "        [0.0134, 0.    , 0.0064, 0.0003, 0.0084, 0.    , 0.071 , 0.    ,\n",
       "         0.0005, 0.    ],\n",
       "        [0.    , 0.    , 0.    , 0.    , 0.    , 0.0007, 0.    , 0.0984,\n",
       "         0.    , 0.0009],\n",
       "        [0.0001, 0.0001, 0.0001, 0.    , 0.0002, 0.    , 0.0008, 0.    ,\n",
       "         0.0987, 0.    ],\n",
       "        [0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.0018,\n",
       "         0.    , 0.0982]]),\n",
       " 'classes_by_label_quality':    Class Index  Label Issues  Inverse Label Issues  Label Noise  \\\n",
       " 0            6           290                   361        0.290   \n",
       " 1            2           170                   110        0.170   \n",
       " 2            4           155                   181        0.155   \n",
       " 3            0           130                   157        0.130   \n",
       " 4            3            72                    23        0.072   \n",
       " 5            5            20                     7        0.020   \n",
       " 6            9            18                    14        0.018   \n",
       " 7            7            16                    30        0.016   \n",
       " 8            1            14                     2        0.014   \n",
       " 9            8            13                    13        0.013   \n",
       " \n",
       "    Inverse Label Noise  Label Quality Score  \n",
       " 0             0.337068                0.710  \n",
       " 1             0.117021                0.830  \n",
       " 2             0.176413                0.845  \n",
       " 3             0.152872                0.870  \n",
       " 4             0.024185                0.928  \n",
       " 5             0.007092                0.980  \n",
       " 6             0.014056                0.982  \n",
       " 7             0.029586                0.984  \n",
       " 8             0.002024                0.986  \n",
       " 9             0.013000                0.987  ,\n",
       " 'overlapping_classes':     Class Index A  Class Index B  Num Overlapping Examples  Joint Probability\n",
       " 0               0              6                       242             0.0242\n",
       " 1               4              6                       206             0.0206\n",
       " 2               2              6                       157             0.0157\n",
       " 3               2              4                        98             0.0098\n",
       " 4               7              9                        27             0.0027\n",
       " 5               0              3                        26             0.0026\n",
       " 6               3              6                        26             0.0026\n",
       " 7               3              4                        26             0.0026\n",
       " 8               5              7                        19             0.0019\n",
       " 9               0              2                        13             0.0013\n",
       " 10              6              8                        13             0.0013\n",
       " 11              2              3                        10             0.0010\n",
       " 12              1              3                         7             0.0007\n",
       " 13              1              6                         7             0.0007\n",
       " 14              5              9                         5             0.0005\n",
       " 15              4              8                         4             0.0004\n",
       " 16              0              8                         4             0.0004\n",
       " 17              5              8                         3             0.0003\n",
       " 18              0              4                         2             0.0002\n",
       " 19              1              8                         1             0.0001\n",
       " 20              1              2                         1             0.0001\n",
       " 21              2              8                         1             0.0001\n",
       " 22              4              5                         0             0.0000\n",
       " 23              6              7                         0             0.0000\n",
       " 24              6              9                         0             0.0000\n",
       " 25              5              6                         0             0.0000\n",
       " 26              4              9                         0             0.0000\n",
       " 27              7              8                         0             0.0000\n",
       " 28              4              7                         0             0.0000\n",
       " 29              0              1                         0             0.0000\n",
       " 30              3              9                         0             0.0000\n",
       " 31              3              8                         0             0.0000\n",
       " 32              3              7                         0             0.0000\n",
       " 33              3              5                         0             0.0000\n",
       " 34              2              9                         0             0.0000\n",
       " 35              2              7                         0             0.0000\n",
       " 36              2              5                         0             0.0000\n",
       " 37              1              9                         0             0.0000\n",
       " 38              1              7                         0             0.0000\n",
       " 39              1              5                         0             0.0000\n",
       " 40              1              4                         0             0.0000\n",
       " 41              0              9                         0             0.0000\n",
       " 42              0              7                         0             0.0000\n",
       " 43              0              5                         0             0.0000\n",
       " 44              8              9                         0             0.0000}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_summary(y, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: T-shirt/top has a score of : 0.8650575876235962 \n",
      "\n",
      "Label: Trouser has a score of : 0.9996353387832642 \n",
      "\n",
      "Label: Pullover has a score of : 0.593125581741333 \n",
      "\n",
      "Label: Dress has a score of : 0.14000502228736877 \n",
      "\n",
      "Label: Coat has a score of : 0.9979678988456726 \n",
      "\n",
      "Label: Sandal has a score of : 0.33959320187568665 \n",
      "\n",
      "Label: Shirt has a score of : 0.9856202602386475 \n",
      "\n",
      "Label: Sneaker has a score of : 0.36190271377563477 \n",
      "\n",
      "Label: Bag has a score of : 0.994206428527832 \n",
      "\n",
      "Label: Ankle boot has a score of : 0.9126272797584534 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cleanlab.rank import get_label_quality_scores\n",
    "quality_scores = get_label_quality_scores(y,pred_probs)\n",
    "for id in range(10):\n",
    "        print(f\"Label: {fashion_dico[str(id)]} has a score of : {quality_scores[id]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to improve the model ?? \n",
    "\n",
    "# 3 solutions : \n",
    "\n",
    "    # Remove all data that cleanlab deems problematic.\n",
    "    # Remove data with quality scores below a threshold. We define or remove a set number of data points.\n",
    "    # Manually mark the data for removal starting from the lowest quality score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b278fd25739fd3dd28fbf117d82d6571fa2cfbc08b56ac88bdc5edd2731ded4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
